{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.style.use(\"bmh\")\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eldata = pd.read_parquet(DATA_DIR.joinpath(\"LD2011_2014.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eldata = eldata.resample(\"1H\", on=\"timestamp\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(eldata!=0).mean().plot()\n",
    "plt.ylabel(\"non-zero %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eldata[eldata!=0].median().sort_values(ascending=False).plot(rot=90)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.ylabel(\"magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# PyTorch Lightning imports\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityLoadDataset(Dataset):\n",
    "    \"\"\"Sample data from electricity load dataset (per household, resampled to one hour).\"\"\"\n",
    "\n",
    "    def __init__(self, df, samples, hist_len=168, fct_len=24):\n",
    "        self.hist_num = hist_len\n",
    "        self.fct_num = fct_len\n",
    "        self.hist_len = pd.Timedelta(hours=hist_len)\n",
    "        self.fct_len = pd.Timedelta(hours=fct_len)\n",
    "        self.offset = pd.Timedelta(hours=1)\n",
    "        self.samples = samples\n",
    "\n",
    "        self.max_ts = df.index.max() - self.hist_len - self.fct_len + self.offset\n",
    "        self.raw_data = df.copy()\n",
    "\n",
    "        assert samples <= self.raw_data[:self.max_ts].shape[0]\n",
    "\n",
    "        self.sample()\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"Sample individual series as needed.\"\"\"\n",
    "\n",
    "        # Calculate actual start for each household\n",
    "        self.clean_start_ts = (self.raw_data!=0).idxmax()\n",
    "\n",
    "        households = []\n",
    "\n",
    "        for hh in self.raw_data.columns:\n",
    "            hh_start = self.clean_start_ts[hh]\n",
    "            hh_nsamples = min(self.samples, self.raw_data.loc[hh_start:self.max_ts].shape[0])\n",
    "\n",
    "            hh_samples = (self.raw_data\n",
    "                          .loc[hh_start:self.max_ts]\n",
    "                          .index\n",
    "                          .to_series()\n",
    "                          .sample(hh_nsamples, replace=False)\n",
    "                          .index)\n",
    "            households.extend([(hh, start_ts) for start_ts in hh_samples])\n",
    "\n",
    "        self.samples = pd.DataFrame(households, columns=(\"household\", \"start_ts\"))\n",
    "\n",
    "        # Adding calendar features\n",
    "        self.raw_data[\"yearly_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.dayofyear / 366)\n",
    "        self.raw_data[\"weekly_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.dayofweek / 7)\n",
    "        self.raw_data[\"daily_cycle\"] = np.sin(2 * np.pi * self.raw_data.index.hour / 24)\n",
    "        self.calendar_features = [\"yearly_cycle\", \"weekly_cycle\", \"daily_cycle\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        household, start_ts = self.samples.iloc[idx]\n",
    "\n",
    "        hs, he = start_ts, start_ts + self.hist_len - self.offset\n",
    "        fs, fe = he + self.offset, he + self.fct_len\n",
    "\n",
    "        hist_data = self.raw_data.loc[hs:, [household] + self.calendar_features].iloc[:self.hist_num]\n",
    "        fct_data = self.raw_data.loc[fs:, [household] + self.calendar_features].iloc[:self.fct_num]\n",
    "\n",
    "        return (torch.Tensor(hist_data.values),\n",
    "                torch.Tensor(fct_data.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ElectricityLoadDataset(eldata, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, fct = ds[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check correct length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fct.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of samples per household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.samples.groupby(\"household\").size().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityLoadDataModule(pl.LightningDataModule):\n",
    "    \"\"\"DataModule for electricity data.\"\"\"\n",
    "\n",
    "    def __init__(self, df,\n",
    "                 train=0.7, \n",
    "                 val=0.2,\n",
    "                 test=0.1,\n",
    "                 samples=100,\n",
    "                 batch_size=64,\n",
    "                 workers=3):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        assert train + val + test <= 1\n",
    "\n",
    "        self.raw_data = df\n",
    "        self.train_size = int(train * df.shape[1])\n",
    "        self.val_size = int(val * df.shape[1])\n",
    "        self.test_size = df.shape[1] - self.train_size - self.val_size\n",
    "\n",
    "        self.samples = samples\n",
    "        self.batch_size = batch_size\n",
    "        self.workers = workers\n",
    "        self.split()\n",
    "\n",
    "    def split(self):\n",
    "        hh_rand = (self.raw_data\n",
    "                   .columns\n",
    "                   .to_series()\n",
    "                   .sample(self.raw_data.shape[1],\n",
    "                           replace=False))\n",
    "\n",
    "        self.train_hh = hh_rand.iloc[:self.train_size].index\n",
    "        self.val_hh = hh_rand.iloc[self.train_size:(self.val_size + self.train_size)].index\n",
    "        self.test_hh = hh_rand.iloc[-self.test_size:].index\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            train_df = self.raw_data[self.train_hh]\n",
    "            val_df = self.raw_data[self.val_hh]\n",
    "\n",
    "            self.train_ds = ElectricityLoadDataset(train_df,\n",
    "                                                   samples=self.samples)\n",
    "            self.val_ds = ElectricityLoadDataset(val_df,\n",
    "                                                 samples=self.samples)\n",
    "\n",
    "        if stage == \"test\" or stage is None:\n",
    "            test_df = self.raw_data[self.test_hh]\n",
    "            self.test_ds = ElectricityLoadDataset(test_df,\n",
    "                                              samples=self.samples)\n",
    "\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, num_workers=self.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ElectricityLoadDataModule(eldata)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dm.train_hh.intersection(dm.val_hh).empty\n",
    "assert dm.train_hh.intersection(dm.test_hh).empty\n",
    "assert dm.train_hh.size + dm.val_hh.size + dm.test_hh.size == 370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityLoadModel(pl.LightningModule):\n",
    "    \"\"\"Encoder network for encoder-decoder forecast model.\"\"\"\n",
    "   \n",
    "    def __init__(self, hist_len=168, fct_len=24, input_size=4, num_layers=1, hidden_units=8, lr=1e-3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hist_len = hist_len\n",
    "        self.fct_len = fct_len\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_units = hidden_units\n",
    "        self.lr = lr\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size,\n",
    "                            hidden_size=self.hidden_units,\n",
    "                            num_layers=self.num_layers,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.mu = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "        self.sigma_raw = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "        self.sigma = nn.Softplus()\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        output, (hh, cc) = self.lstm(x)\n",
    "        mu = self.mu(output)\n",
    "        sigma = self.sigma(self.sigma_raw(output))\n",
    "        return output, mu, sigma, hh, cc\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        combined_input = torch.cat(batch, dim=1)\n",
    "\n",
    "        # Pushing through the network\n",
    "        out, mu, sigma, hh, cc = self(combined_input[:, :-1, :])\n",
    "\n",
    "        return self.loss(mu, sigma, combined_input[:, 1:, [0]])\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        combined_input = torch.cat(batch, dim=1)\n",
    "\n",
    "        # Pushing through the network\n",
    "        out, mu, sigma, hh, cc = self(combined_input[:, :-1, :])\n",
    "\n",
    "        loss = self.loss(mu, sigma, combined_input[:, 1:, [0]])\n",
    "        self.log('val_logprob', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "    def sample(self, x, samples):\n",
    "        # Handle single stream or multiple streams\n",
    "        x = x.view(-1, self.hist_len, 4)\n",
    "\n",
    "        # Initial pass - `mu(T+1)` and `sigma(T+1)` are ready\n",
    "        out, mu, sigma, hh_initial, cc_initial = self(x)\n",
    "\n",
    "        # Sample from the distribution\n",
    "        gaussian = torch.distributions.normal.Normal(mu[:, -1, -1], sigma[:, -1, -1])\n",
    "        initial_sample = gaussian.sample((samples,))\n",
    "\n",
    "        # Getting calendar features\n",
    "        # TODO: fix calendar features, weekly and yearly\n",
    "        calendar_features = x[:, -self.fct_len:, 1:]\n",
    "        \n",
    "        all_samples = []\n",
    "\n",
    "        # Iterating over samples\n",
    "        for sample in range(samples):\n",
    "            current_sample = initial_sample[sample]\n",
    "\n",
    "            # We want output to be `(fct_len, batch_size, samples)`\n",
    "            local_samples = [current_sample.view(1, -1, 1)]\n",
    "            \n",
    "            # Initialize hidden and cell state to encoder output\n",
    "            hh, cc = hh_initial, cc_initial\n",
    "\n",
    "            # Iterating over time steps\n",
    "            for step in range(self.fct_len - 1):\n",
    "\n",
    "                # Input tensor for this step\n",
    "                step_in = torch.cat([current_sample.view(-1, 1, 1),\n",
    "                                     calendar_features[:, [step], :]], dim=-1)\n",
    "\n",
    "                step_out, mu, sigma, hh, cc = self(step_in, (hh, cc))\n",
    "\n",
    "                # Sampling the next step value\n",
    "                gaussian = torch.distributions.normal.Normal(mu[:, -1, -1], sigma[:, -1, -1])\n",
    "                current_sample = gaussian.sample((1,))\n",
    "                \n",
    "                # Storing the samples for this time step\n",
    "                local_samples.append(current_sample.unsqueeze(-1))\n",
    "\n",
    "            # Storing all samples for this sample\n",
    "            all_samples.append(torch.cat(local_samples, dim=0))\n",
    "        return torch.cat(all_samples, -1)\n",
    "\n",
    "    def loss(self, mu, sigma, y):\n",
    "        # Distribution with generated `mu` and `sigma`\n",
    "        gaussian = torch.distributions.normal.Normal(mu, sigma)\n",
    "\n",
    "        # Log-likelihood\n",
    "        L = gaussian.log_prob(y)\n",
    "\n",
    "        return -torch.mean(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = eldata / eldata[eldata!=0].mean() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dm = ElectricityLoadDataModule(scaled_data, batch_size=128)\n",
    "model = ElectricityLoadModel(lr=1e-3, hidden_units=64, num_layers=1)\n",
    "trainer = pl.Trainer(max_epochs=5, progress_bar_refresh_rate=1, gpus=1)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example forecasts\n",
    "\n",
    "Although the model must be trained in full longer and with larger number of layers, we still can capture the logistics of making the forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(stage=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dm.test_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.sample(X, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.mean(dim=-1).numpy()[:,8])\n",
    "plt.plot(y[8, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
